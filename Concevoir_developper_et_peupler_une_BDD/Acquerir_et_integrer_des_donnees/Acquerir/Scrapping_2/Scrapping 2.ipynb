{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contexte du projet\n",
    "\n",
    "Votre entreprise vous demande de disposer, en base de données, des titres des articles du site 20 Minutes.\n",
    "\n",
    "![voir l'image jointe](Images/vue_site_20minutes.png)\n",
    "\n",
    "Chaque jour, un script ira collecter ces titres, ainsi que leur catégorie, et les placera en base de données, avec un horodatage.\n",
    "\n",
    "On doit pouvoir ainsi, par exemple, pouvoir récupérer tous les titres des articles concernant \"Roland Garros\", au mois de mai 2022."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rechercher l'organisation HTML du site internet concerné, et notamment les noms et type de balise permettant de repérer les titres et catégories de articles."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balise contenant un article : `<article>`\n",
    "\n",
    "Dans l'article :\n",
    "\n",
    "- `<h2 class = \"teaser-title\">` : Titre\n",
    "\n",
    "- `<div class = \"teaser-headline\">` : Catégorie du titre\n",
    "\n",
    "- `<span class = \"counterbar-item datetime\">` : Heure de l'article"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Ecrire un script python qui récupère ces informations par scrapping, et les affiche dans la console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Récupération de la page HTML\n",
    "url = \"https://www.20minutes.fr/\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "articles = soup.find_all('article')\n",
    "\n",
    "for article in articles:\n",
    "\n",
    "    try :\n",
    "        heure = article.find('span', class_ = \"counterbar-item datetime\").text\n",
    "\n",
    "    except AttributeError :\n",
    "        continue\n",
    "\n",
    "    if heure.find(':') != -1:\n",
    "\n",
    "        print(f\"Titre : {article.find('h2', class_ ='teaser-title').text}\")\n",
    "        print(f\"Catégorie : {article.find('div', class_ ='teaser-headline').text}\")\n",
    "        print(f\"Heure : {heure}\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Créer une base de données avec une table articles_20minutes pour stocker date, catégorie et titre des articles."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des fonctions pour se connecter à la base de donnée et insérer des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sq\n",
    "import mysql.connector as cnt\n",
    "\n",
    "# Fonction de connexion à la base de données\n",
    "def connect_db(host, user, pswd, database = None):\n",
    "    db = cnt.connect(\n",
    "        host = host,\n",
    "        user = user,\n",
    "        passwd = pswd,\n",
    "        database = database\n",
    "    )\n",
    "    return(db)\n",
    "\n",
    "# Fonction d'execution de requêtes SQL\n",
    "def exe(db, request, value = None, verbose = False, name = False):\n",
    "    cursor = db.cursor(buffered = True)\n",
    "    \n",
    "    if value:\n",
    "        cursor.execute(request, value)\n",
    "\n",
    "    else :\n",
    "        cursor.execute(request)\n",
    "\n",
    "    db.commit()\n",
    "    \n",
    "    if verbose:\n",
    "        result = cursor.fetchall()\n",
    "        if name:\n",
    "            result.insert(0, cursor.column_names)\n",
    "        return(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la base de données et de la table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = connect_db('192.168.20.118', 'grogu', 'grogu')\n",
    "\n",
    "queries = ['CREATE DATABASE IF NOT EXISTS scrapping']\n",
    "\n",
    "queries.append(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS scrapping.articles_20minutes(\n",
    "        Code INT NOT NULL AUTO_INCREMENT,\n",
    "        Date DATETIME NOT NULL,\n",
    "        Categorie TEXT NOT NULL,\n",
    "        Titre TEXT NOT NULL,\n",
    "        PRIMARY KEY (Code)\n",
    "    )ENGINE = InnoDB;\n",
    "\"\"\")\n",
    "\n",
    "for query in queries:\n",
    "    exe(db, query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Screenshot de la base de données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](Images/BDD.jpg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Modifier le script python pour inscrire les données dans la base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Fonction de conversion Heure:Minutes --> Datetime\n",
    "def convert_time(str_time):\n",
    "    liste_time = str_time.split(\":\")\n",
    "\n",
    "    new_time = datetime.datetime.now()\n",
    "\n",
    "    new_time = new_time.replace(hour = int(liste_time[0]) - 1, minute = int(liste_time[1]) - 1, second = 0)\n",
    "\n",
    "    return(new_time)\n",
    "\n",
    "# Scrapping\n",
    "\n",
    "datas = []\n",
    "\n",
    "url = \"https://www.20minutes.fr/\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "\n",
    "articles = soup.find_all('article')\n",
    "\n",
    "for article in articles:\n",
    "\n",
    "    try :\n",
    "        heure = article.find('span', class_ = \"counterbar-item datetime\").text\n",
    "\n",
    "    except AttributeError :\n",
    "        continue\n",
    "\n",
    "    if heure.find(':') != -1:\n",
    "# Création d'une liste regroupant les données récupérées\n",
    "        datas.append([convert_time(heure), article.find('div', class_ ='teaser-headline').text, article.find('h2', class_ ='teaser-title').text])\n",
    "\n",
    "\n",
    "# Insertion dans la base de données\n",
    "db = connect_db('192.168.20.118', 'grogu', 'grogu', database = 'scrapping')\n",
    "\n",
    "for data in datas :\n",
    "\n",
    "    query = f\"\"\"INSERT INTO articles_20minutes (Date, Categorie, Titre) VALUES (\"{data[0]}\", \"{data[1]}\", \"{data[2]}\");\"\"\"\n",
    "\n",
    "    exe(db, query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](Images/BDD_1.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
