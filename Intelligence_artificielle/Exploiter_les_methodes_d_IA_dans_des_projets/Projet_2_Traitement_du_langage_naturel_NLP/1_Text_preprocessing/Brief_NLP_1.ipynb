{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eccf7b97",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "In any machine learning task, cleaning or preprocessing the data is as important as building the model. Textual data is one of the least structured forms of data available and when it comes to processing human language, it is too complex. \n",
    "In this Brief we will work on preprocessing textual data using [NLTK](http://www.nltk.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20d29f9",
   "metadata": {},
   "source": [
    "## Veille technologique: Natural Language processing (NLP)\n",
    "1- How NLP is used in our lives  \n",
    "2- How Fecebook, Google and Amazon use NLP  \n",
    "3- Text data preparation   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df871de1",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aecb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "import nltk, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b7e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK data \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79a5cf",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "In this section we will use [NLTK](http://www.nltk.org) to net a text from [wikipid√©a](https://en.wikipedia.org/wiki/Natural_language_processing) on the definition of NLP \n",
    "\n",
    "\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6bf760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase: Put all text in lower case\n",
    "\n",
    "text = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\"\"\"\n",
    "\n",
    "text = text.lower()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "\n",
    "text = re.sub(r'[^\\w\\s]', '', text)\n",
    " \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3cdd6",
   "metadata": {},
   "source": [
    "### Word Tokenization\n",
    "\n",
    "Tokenization([Tokenize](https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.casual)) consists in dividing strings into individual words without blanks or tabs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf7be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Tokenization\n",
    "\n",
    "# text = text.split(' ')\n",
    "\n",
    "# OR\n",
    "\n",
    "text = nltk.tokenize.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec18ba3",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "Stop words are words that do not add significant meaning to the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad98be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NLTK to list stop words and remove them from the text.\n",
    "\n",
    "text = [word for word in text if word not in nltk.corpus.stopwords.words('english')] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25588009",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "Etymology is the process of reducing words to their root, base or form ([Stemming](https://en.wikipedia.org/wiki/Stemming) )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce47387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "\n",
    "text = [nltk.stem.PorterStemmer().stem(word) for word in text] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5418434",
   "metadata": {},
   "source": [
    "## Function development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop each step of the text preprocessing in a function\n",
    "\n",
    "def text_preproc(text):\n",
    "    import nltk, re\n",
    "\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "\n",
    "    text = nltk.tokenize.word_tokenize(text)\n",
    "\n",
    "    text = [word for word in text if word not in nltk.corpus.stopwords.words('english')] \n",
    "\n",
    "    text = [nltk.stem.PorterStemmer().stem(word) for word in text] \n",
    "\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3610110",
   "metadata": {},
   "source": [
    "# What about Twitter messages !! :)\n",
    "\n",
    "In this part we will apply the text preprocessing steps on a database of Twitters messages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c886a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python library for NLP\n",
    "\n",
    "import nltk, random\n",
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "# Import Sample Twitter dataset from NLTK\n",
    "\n",
    "nltk.download('twitter_samples') \n",
    "\n",
    "# Import library for visualization\n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979b2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "\n",
    "data_negative = twitter_samples.strings(\"negative_tweets.json\")\n",
    "data_negative\n",
    "\n",
    "data_positive = twitter_samples.strings(\"positive_tweets.json\")\n",
    "data_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061ed30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print positive in greeen\n",
    "\n",
    "sample_positive = []\n",
    "sample_negative = []\n",
    "\n",
    "\n",
    "for _ in range(5):\n",
    "    sample_positive.append(data_positive[random.randint(0, len(data_positive))])\n",
    "\n",
    "for i in range(0, 5):\n",
    "    plt.text(0, 0.01 + (i * 0.1), sample_positive[i], color = 'green', fontsize = 7)\n",
    "\n",
    "# print negative in red\n",
    "\n",
    "for _ in range(5):\n",
    "    sample_negative.append(data_negative[random.randint(0, len(data_negative))])\n",
    "\n",
    "for i in range(5, 10):\n",
    "    plt.text(0, 0.01 + (i * 0.1), sample_negative[i - 5], color = 'red', fontsize = 7)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "45bb1cb4637e4034484920e5cfb24c9afd84b0847d6c36e39edd3067d3a05462"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
