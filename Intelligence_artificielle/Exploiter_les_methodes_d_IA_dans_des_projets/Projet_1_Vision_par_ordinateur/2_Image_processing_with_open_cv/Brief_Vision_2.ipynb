{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing : filtering, thresholding, and object counting with opencv\n",
    "\n",
    "An introduction to the opencv library "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the opencv library\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(cv2.__version__)\n",
    "\n",
    "# read the image 'bois' (with imread)\n",
    "\n",
    "img = cv2.imread('Images/bois.png')\n",
    "\n",
    "# show image\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the size of the image\n",
    "\n",
    "print(f\"Largeur : {img.shape[1]}\\nHauteur : {img.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the image has three colors R,G,B. display the values of the three colors for the pixel x = 150, and y = 100\n",
    "\n",
    "img[100, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop a part of the image (select a small part from the coordinates)\n",
    "cropped = img[100:200, 150:300]\n",
    "\n",
    "plt.imshow(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image to 200x200 pixels\n",
    "\n",
    "resized = cv2.resize(img, (200, 200), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# show resized\n",
    "\n",
    "plt.imshow(resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize without affecting the image\n",
    "\n",
    "resized = cv2.resize(img[0:1365, 0:1365], (200, 200))\n",
    "plt.imshow(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate an image -45\n",
    "M = cv2.getRotationMatrix2D((img.shape[1]/2,img.shape[0]/2),-45,1) \n",
    "rotate_45 = cv2.warpAffine(img,M,(img.shape[1],img.shape[0])) \n",
    "plt.imshow(rotate_45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw on the picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a rectangle\n",
    "rectangle = img.copy()\n",
    "cv2.rectangle(rectangle, (1000,700),(10,10),(0,255,0),3)\n",
    "plt.imshow(rectangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a circle\n",
    "circle = img.copy()\n",
    "cv2.circle(circle,(1000,700), 63, (0,0,255), -1)\n",
    "plt.imshow(circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image filtering\n",
    "\n",
    "* Blur\n",
    "* Gaussian blur\n",
    "* Median blur\n",
    "* Sharpening\n",
    "* Bilateral blur\n",
    "* Bilateral filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and display the \"wood\" image\n",
    "\n",
    "img = cv2.imread('Images/bois.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"cv2.filter2D\" method with a kernel of size 2\n",
    "\n",
    "kernel = np.ones((2, 2), np.float32)/4\n",
    "\n",
    "blur = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "plt.imshow(blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply blur with a kernel size of 5x5\n",
    "\n",
    "kernel = np.ones((5, 5), np.float32)/25\n",
    "\n",
    "blur = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "plt.imshow(blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian blur\n",
    "\n",
    "blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "plt.imshow(blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median blur\n",
    "\n",
    "blur = cv2.medianBlur(img,5)\n",
    "plt.imshow(blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharpening\n",
    "\n",
    "kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 5,-1],\n",
    "                   [0, -1, 0]])\n",
    "image_sharp = cv2.filter2D(src=img, ddepth=-1, kernel=kernel)\n",
    "\n",
    "plt.imshow(image_sharp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bilateral filtering\n",
    "\n",
    "blur = cv2.bilateralFilter(img,9,75,75)\n",
    "plt.imshow(blur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image threshold\n",
    "\n",
    "Using the image \"sudoku\" apply:\n",
    "* Binary Thresholding\n",
    "* Otsu thresholding\n",
    "* Adaptive thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading sudoku\n",
    "\n",
    "img = cv2.imread('Images/sudoku.jpg')\n",
    "\n",
    "# show image\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a binary threshold of 127\n",
    "\n",
    "thresh, img_thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.imshow(img_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a binary threshold of 30\n",
    "\n",
    "thresh, img_thresh = cv2.threshold(img, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.imshow(img_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a binary threshold of 240\n",
    "\n",
    "thresh, img_thresh = cv2.threshold(img, 240, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.imshow(img_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply \"Otsu\" thresholding\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "thresh, img_thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "plt.imshow(img_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appliquer \"Seuil adaptatif\"\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "img_thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "plt.imshow(img_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge detection\n",
    "\n",
    "* Sobel\n",
    "* Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the sobel method to detect the edges\n",
    "# You can use other images of your choice\n",
    "\n",
    "img = cv2.imread('Images/Image_02.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "sobelx = cv2.Sobel(img,-1,1,0,ksize=5)\n",
    "sobely = cv2.Sobel(img,-1,0,1,ksize=5)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,1),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')\n",
    "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,4),plt.imshow(sobely,cmap = 'gray')\n",
    "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,2),plt.imshow(sobely+sobelx,cmap = 'gray')\n",
    "plt.title('Sobel X + Y'), plt.xticks([]), plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny\n",
    "\n",
    "img = cv2.imread('Images/sudoku.jpg')\n",
    "\n",
    "edges = cv2.Canny(img, 150, 200)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image 02\n",
    "# do a search on the internet to detect the contours of the objects in image_02\n",
    "\n",
    "img= cv2.imread(\"Images/image_02.png\")\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "_,edge = cv2.threshold(gray,240,256,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "contours,_ = cv2.findContours(edge,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "gray = cv2.drawContours(img, contours,-1,(255,0,0),5)\n",
    "\n",
    "plt.imshow(gray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting objects\n",
    "\n",
    "len(contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge\n",
    "Count the number of objects in image 03 with the previous code.\n",
    "- What do you notice?\n",
    "- Use the Watershed algorithm to detect and separate the connected objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TODO **\n",
    "- Find out how to count the blobs.\n",
    "- Color/label the blobs\n",
    "- Find the diameter of the blobs\n",
    "\n",
    "Go to see\n",
    "- https://towardsdatascience.com/image-processing-with-python-blob-detection-using-scikit-image-5df9a8380ade\n",
    "- https://scikit-image.org/docs/0.19.x/auto_examples/segmentation/plot_watershed.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find out how to count the blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Images/image_03.jpg\")\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Images/image_03.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "contours,_ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img_contour = cv2.drawContours(img, contours, -1, (255,0,0), 5)\n",
    "\n",
    "plt.imshow(img_contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "# sure background area\n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "# Finding sure foreground area\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "_, sure_fg = cv2.threshold(dist_transform, 0.55*dist_transform.max(),255,0)\n",
    "\n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "# Marker labelling\n",
    "_, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "\n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "\n",
    "# Perform the watershed algorithm\n",
    "markers = cv2.watershed(img, markers)\n",
    "\n",
    "# Color the regions\n",
    "img[markers == -1] = [255,0,0]\n",
    "\n",
    "plt.figure(figsize = (15, 15))\n",
    "\n",
    "plt.subplot(221),plt.imshow(sure_bg, cmap = 'gray')\n",
    "plt.title('sure_bg'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(222),plt.imshow(sure_fg, cmap = 'gray')\n",
    "plt.title('Sure_fg'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(223),plt.imshow(unknown, cmap = 'gray')\n",
    "plt.title('Unknown'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(224),plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Result'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "contours,_ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "gray = cv2.drawContours(img, contours,-1,(255,0,0),5)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "contours,_ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cv2.drawContours(img, contours,-1,(255,0,0),5)\n",
    "\n",
    "print(f\"Il y a {len(contours)} contours.\")\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Color/label the blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "\n",
    "img = cv2.imread(\"Images/image_03.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_, image = cv2.threshold(gray, 82, 256, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# Now we want to separate the two objects in image\n",
    "# Generate the markers as local maxima of the distance to the background\n",
    "distance = ndi.distance_transform_edt(image)\n",
    "coords = peak_local_max(distance, footprint=np.ones((15, 15)), labels=image)\n",
    "mask = np.zeros(distance.shape, dtype=bool)\n",
    "mask[tuple(coords.T)] = True\n",
    "markers, _ = ndi.label(mask)\n",
    "labels = watershed(-distance, markers, mask=image)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(9, 3), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(image, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Overlapping objects')\n",
    "ax[1].imshow(-distance, cmap=plt.cm.gray)\n",
    "ax[1].set_title('Distances')\n",
    "ax[2].imshow(labels, cmap=plt.cm.nipy_spectral)\n",
    "ax[2].set_title('Separated objects')\n",
    "\n",
    "for a in ax:\n",
    "    a.set_axis_off()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Find the diameter of the blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "\n",
    "props = measure.regionprops(labels, intensity_image=image)\n",
    "\n",
    "plt.imshow(labels, cmap=plt.cm.nipy_spectral)\n",
    "plt.title('Separated objects')\n",
    "\n",
    "for prop in props:\n",
    "    diameter = prop.equivalent_diameter\n",
    "    print(f\"Le blob numéro {prop.label} a un diamètre de {round(diameter, 2)} pixels\")\n",
    "    y, x = prop.centroid\n",
    "    plt.text(x, y, f\"{prop.label}\", ha=\"center\", va=\"center\", color=(0,0,0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bravo !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
