{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for automatic detection of pneumonia from chest X-ray images.\n",
    "\n",
    "Pneumonia is a respiratory infection caused by bacteria or viruses; it affects many people, especially in developing and underdeveloped countries with high levels of pollution. Pneumonia causes pleural effusion, which means that fluid fills the lung, leading to breathing difficulties. Early diagnosis of pneumonia is crucial to ensure curative treatment and increase survival rates. Chest X-rays are the most common method used to diagnose pneumonia. However, the examination of chest radiographs is a difficult task and is subject to subjective variability. In this brief, you will develop a computer-aided diagnostic system for automatic detection of pneumonia from chest X-ray images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Keras\n",
    "\n",
    "- https://victorzhou.com/blog/intro-to-cnns-part-1/\n",
    "- https://victorzhou.com/blog/keras-cnn-tutorial/\n",
    "- https://www.tensorflow.org/tutorials/images/cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages here\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import datasets, layers, models, utils\n",
    "import os, random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path for each data set\n",
    "# train\n",
    "\n",
    "train_path = \"chest_xray/train/\"\n",
    "\n",
    "# val\n",
    "\n",
    "val_path = \"chest_xray/val/\"\n",
    "\n",
    "# test\n",
    "\n",
    "test_path = \"chest_xray/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the size of the image\n",
    "\n",
    "img_width, img_height = 280, 280"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to each type\n",
    "# Get the path to the normal and pneumonia sub-directories\n",
    "train_normal_path = train_path + \"NORMAL/\"\n",
    "train_pneumonia_path = train_path + \"PNEUMONIA/\"\n",
    "\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "\n",
    "for img in os.listdir(train_normal_path):\n",
    "    # load image\n",
    "\n",
    "    img = tf.keras.utils.load_img(train_normal_path + img)\n",
    "    \n",
    "    # resize the image\n",
    "    \n",
    "    img = tf.image.resize(img, (img_width, img_height))\n",
    "\n",
    "\n",
    "    # there are images with one or two dimensions (None, None, 1). put the image (None,None,1) --> (28,28,3) \n",
    "        # repeat the last dimension three times\n",
    "    if img.get_shape()[2] != 3:\n",
    "        img = tf.concat((img, img, img), axis=2)\n",
    "        print(\"Found wrong Dim img\")\n",
    "\n",
    "    # normalize the image\n",
    "\n",
    "    img = img/255\n",
    "    \n",
    "    # add a label (use to_categorical from Keras)\n",
    "\n",
    "    label = utils.to_categorical(0, num_classes = 2, dtype = 'float32')\n",
    "    \n",
    "    # load the image and the label\n",
    "\n",
    "    train_images.append(img)\n",
    "    train_labels.append(label)\n",
    "\n",
    "\n",
    "for img in os.listdir(train_pneumonia_path):\n",
    "    # load image\n",
    "\n",
    "    img = tf.keras.utils.load_img(train_pneumonia_path + img)\n",
    "    \n",
    "    # resize the image\n",
    "    \n",
    "    img = tf.image.resize(img, (img_width, img_height))\n",
    "\n",
    "    # there are images with one or two dimensions (None, None, 1). put the image (None,None,1) --> (28,28,3) \n",
    "        # repeat the last dimension three times\n",
    "    if img.get_shape()[2] != 3:\n",
    "        img = tf.concat((img, img, img), axis=2)\n",
    "        print(\"Found wrong Dim img\")\n",
    "\n",
    "    # normalize the image\n",
    "\n",
    "    img = img/255\n",
    "    \n",
    "    # add a label (use to_categorical from Keras)\n",
    "\n",
    "    label = utils.to_categorical(1, num_classes = 2, dtype = 'float32')\n",
    "    \n",
    "    # load the image and the label\n",
    "\n",
    "    train_images.append(img)\n",
    "    train_labels.append(label)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing test data\n",
    "normal_test_cases_dir = test_path + \"NORMAL/\"\n",
    "pneumonia_test_cases_dir = test_path + \"PNEUMONIA/\"\n",
    "\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for img in os.listdir(normal_test_cases_dir):\n",
    "\n",
    "    # load image\n",
    "    img = tf.keras.utils.load_img(normal_test_cases_dir + img)\n",
    "    \n",
    "    # resize the image \n",
    "    \n",
    "    img = tf.image.resize(img, (img_width, img_height))\n",
    "\n",
    "    # there are images with one or two dimensions (None, None, 1). put the image (None,None,1) --> (28,28,3) \n",
    "        # repeat the last dimension three times\n",
    "    if img.get_shape()[2] != 3:\n",
    "        img = tf.concat((img, img, img), axis=2)\n",
    "        print(\"Found wrong Dim img\")\n",
    "\n",
    "\n",
    "    # normalize the image\n",
    "\n",
    "    img = img/255\n",
    "    \n",
    "    # add a label (use to_categorical from Keras)\n",
    "\n",
    "    label = utils.to_categorical(0, num_classes = 2, dtype = 'float32')\n",
    "    \n",
    "    # load the image and the label\n",
    "\n",
    "    test_images.append(img)\n",
    "    test_labels.append(label)\n",
    "\n",
    "\n",
    "for img in os.listdir(pneumonia_test_cases_dir):\n",
    "\n",
    "    # load image\n",
    "    img = tf.keras.utils.load_img(pneumonia_test_cases_dir + img)\n",
    "    \n",
    "    # resize the image (28*28)\n",
    "    \n",
    "    img = tf.image.resize(img, (img_width, img_height))\n",
    "\n",
    "    # there are images with one or two dimensions (None, None, 1). put the image (None,None,1) --> (28,28,3) \n",
    "        # repeat the last dimension three times\n",
    "    if img.get_shape()[2] != 3:\n",
    "        img = tf.concat((img, img, img), axis=2)\n",
    "        print(\"Found wrong Dim img\")\n",
    "\n",
    "    # normalize the image\n",
    "\n",
    "    img = img/255\n",
    "    \n",
    "    # add a label (use to_categorical from Keras)\n",
    "\n",
    "    label = utils.to_categorical(1, num_classes = 2, dtype = 'float32')\n",
    "    \n",
    "    # load the image and the label\n",
    "\n",
    "    test_images.append(img)\n",
    "    test_labels.append(label)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing val data\n",
    "normal_val_cases_dir = val_path + \"NORMAL/\"\n",
    "pneumonia_val_cases_dir = val_path + \"PNEUMONIA/\"\n",
    "\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "\n",
    "val_images = []\n",
    "val_labels = []\n",
    "\n",
    "\n",
    "for img in os.listdir(normal_val_cases_dir):\n",
    "\n",
    "    # load image\n",
    "    img = tf.keras.utils.load_img(normal_val_cases_dir + img)\n",
    "    \n",
    "    # resize the image\n",
    "    \n",
    "    img = tf.image.resize(img, (img_width, img_height))\n",
    "\n",
    "    # there are images with one or two dimensions (None, None, 1). put the image (None,None,1) --> (28,28,3) \n",
    "        # repeat the last dimension three times\n",
    "    if img.get_shape()[2] != 3:\n",
    "        img = tf.concat((img, img, img), axis=2)\n",
    "        print(\"Found wrong Dim img\")\n",
    "\n",
    "\n",
    "    # normalize the image\n",
    "\n",
    "    img = img/255\n",
    "    \n",
    "    # add a label (use to_categorical from Keras)\n",
    "\n",
    "    label = utils.to_categorical(0, num_classes = 2, dtype = 'float32')\n",
    "    \n",
    "    # load the image and the label\n",
    "\n",
    "    val_images.append(img)\n",
    "    val_labels.append(label)\n",
    "\n",
    "for img in os.listdir(pneumonia_val_cases_dir):\n",
    "\n",
    "    # load image\n",
    "    img = tf.keras.utils.load_img(pneumonia_val_cases_dir + img)\n",
    "    \n",
    "    # resize the image\n",
    "    \n",
    "    img = tf.image.resize(img, (img_width, img_height))\n",
    "\n",
    "    # there are images with one or two dimensions (None, None, 1). put the image (None,None,1) --> (28,28,3) \n",
    "        # repeat the last dimension three times\n",
    "    if img.get_shape()[2] != 3:\n",
    "        img = tf.concat((img, img, img), axis=2)\n",
    "        print(\"Found wrong Dim img\")\n",
    "\n",
    "    # normalize the image\n",
    "\n",
    "    img = img/255\n",
    "    \n",
    "    # add a label (use to_categorical from Keras)\n",
    "\n",
    "    label = utils.to_categorical(1, num_classes = 2, dtype = 'float32')\n",
    "    \n",
    "    # load the image and the label\n",
    "\n",
    "    val_images.append(img)\n",
    "    val_labels.append(label)\n",
    "\n",
    "val_images = np.array(val_images)\n",
    "val_labels = np.array(val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for the creation of the CNN model\n",
    "\n",
    "import keras.layers\n",
    "import keras.models\n",
    "\n",
    "# Create CNN model here\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding=\"valid\", activation=\"relu\", input_shape=(img_width, img_height, 3)))\n",
    "model.add(layers.MaxPooling2D(pool_size = (2, 2), strides=None, padding=\"valid\"))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding=\"valid\", activation=\"relu\", input_shape=(img_width, img_height, 3)))\n",
    "model.add(layers.MaxPooling2D(pool_size = (2, 2), strides=None, padding=\"valid\"))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding=\"valid\", activation=\"relu\", input_shape=(img_width, img_height, 3)))\n",
    "model.add(layers.MaxPooling2D(pool_size = (2, 2), strides=None, padding=\"valid\"))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), strides=(1, 1), padding=\"valid\", activation=\"relu\", input_shape=(img_width, img_height, 3)))\n",
    "model.add(layers.MaxPooling2D(pool_size = (2, 2), strides=None, padding=\"valid\"))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), strides=(1, 1), padding=\"valid\", activation=\"relu\", input_shape=(img_width, img_height, 3)))\n",
    "model.add(layers.MaxPooling2D(pool_size = (2, 2), strides=None, padding=\"valid\"))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(layers.Dense(activation = 'relu', units = 128))\n",
    "model.add(layers.Dense(activation = 'relu', units = 64))\n",
    "model.add(layers.Dense(activation = 'sigmoid', units = 2))\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Require libraries installation\n",
    "# from keras.utils import plot_model\n",
    "# plot_model(model,show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "\n",
    "# Creating callbacks\n",
    "early = EarlyStopping(monitor='val_loss', mode='min', patience=3)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1, factor=0.3, min_lr=0.000001)\n",
    "callbacks_list = [ early, learning_rate_reduction]\n",
    "\n",
    "# train the model\n",
    "history = model.fit(x = train_images, y = train_labels, validation_data = (val_images, val_labels), epochs = 10, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"The accuracy of the model is:\")\n",
    "print(f\" accuracy : {round(test_acc, 4)*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# display the confusion matrix\n",
    "\n",
    "pred = model.predict(test_images)\n",
    "\n",
    "print(f\"Matrice de confusion: \\n{confusion_matrix(np.argmax(test_labels, axis=1), np.argmax(pred, axis=1))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Calculer Precision et Recall\n",
    "\n",
    "print(classification_report(np.argmax(test_labels, axis=1), np.argmax(pred, axis=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
