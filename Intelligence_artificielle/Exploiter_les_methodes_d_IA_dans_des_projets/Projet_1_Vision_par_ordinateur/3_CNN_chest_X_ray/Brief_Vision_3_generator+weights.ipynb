{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for automatic detection of pneumonia from chest X-ray images.\n",
    "\n",
    "Pneumonia is a respiratory infection caused by bacteria or viruses; it affects many people, especially in developing and underdeveloped countries with high levels of pollution. Pneumonia causes pleural effusion, which means that fluid fills the lung, leading to breathing difficulties. Early diagnosis of pneumonia is crucial to ensure curative treatment and increase survival rates. Chest X-rays are the most common method used to diagnose pneumonia. However, the examination of chest radiographs is a difficult task and is subject to subjective variability. In this brief, you will develop a computer-aided diagnostic system for automatic detection of pneumonia from chest X-ray images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Keras\n",
    "\n",
    "- https://victorzhou.com/blog/intro-to-cnns-part-1/\n",
    "- https://victorzhou.com/blog/keras-cnn-tutorial/\n",
    "- https://www.tensorflow.org/tutorials/images/cnn\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization, Flatten, Dense\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.metrics import Precision, Recall\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Defining paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path for each data set\n",
    "# train\n",
    "\n",
    "train_path = \"chest_xray/train/\"\n",
    "\n",
    "# val\n",
    "\n",
    "val_path = \"chest_xray/val/\"\n",
    "\n",
    "# test\n",
    "\n",
    "test_path = \"chest_xray/test/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Defining image size and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the size of the image\n",
    "\n",
    "img_width, img_height = 192, 192\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Defining ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Image Data Generator for Train Set\n",
    "image_gen = ImageDataGenerator(\n",
    "  rescale = 1./255,\n",
    "  shear_range = 0.2,\n",
    "  zoom_range = 0.2,\n",
    "  horizontal_flip = True\n",
    ")\n",
    "\n",
    "# Create Image Data Generator for Test/Validation Set\n",
    "test_data_gen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing train data\n",
    "train = image_gen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size = (img_height, img_width),\n",
    "    color_mode = 'grayscale',\n",
    "    class_mode = 'binary',\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing test data\n",
    "test = test_data_gen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size = (img_height, img_width),\n",
    "    color_mode = 'grayscale',\n",
    "    shuffle = False, \n",
    "    class_mode = 'binary',\n",
    "    batch_size = batch_size,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing val data\n",
    "val = test_data_gen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size = (img_height, img_width),\n",
    "    color_mode = 'grayscale',\n",
    "    shuffle = False, \n",
    "    class_mode = 'binary',\n",
    "    batch_size = batch_size,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Viewing some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0 : \"NORMAL\", 1 : \"PNEUMONIA\"}\n",
    "plt.figure(figsize = (12, 12))\n",
    "\n",
    "for i in range(0, 10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    for X_batch, Y_batch in train:\n",
    "        image = X_batch[0]        \n",
    "        plt.title(labels.get(Y_batch[0]))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.squeeze(image), cmap = \"gray\", interpolation = \"nearest\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation = \"relu\", padding = 'same', input_shape = (img_width, img_height, 1)))\n",
    "model.add(MaxPooling2D(padding = 'same'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation = \"relu\", padding = 'same'))\n",
    "model.add(MaxPooling2D(padding = 'same'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation = \"relu\", padding = 'same'))\n",
    "model.add(MaxPooling2D(padding = 'same'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation = \"relu\", padding = 'same'))\n",
    "model.add(MaxPooling2D(padding = 'same'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation = \"relu\", padding = 'same'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy', Precision(name = 'precision'), Recall(name = 'recall')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Require libraries installation\n",
    "# plot_model(model,show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Creating callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating callbacks\n",
    "early = EarlyStopping(\n",
    "    verbose = 1, \n",
    "    monitor = 'val_accuracy', \n",
    "    mode = 'min',\n",
    "    patience = 10\n",
    ")\n",
    "\n",
    "LR_reduction = ReduceLROnPlateau(\n",
    "    verbose = 1, \n",
    "    monitor = 'val_loss', \n",
    "    mode = 'min',\n",
    "    factor = 0.2, \n",
    "    min_lr = 0.000001,\n",
    "    patience = 3\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    '/content/drive/MyDrive/Colab Notebooks/Models/THE_BEST_OF_THE_BEST.hdf5', \n",
    "    verbose = 1, \n",
    "    monitor = 'val_accuracy', \n",
    "    mode = 'min',\n",
    "    save_best_only = True\n",
    ")\n",
    "\n",
    "\n",
    "callbacks_list = [early, LR_reduction, checkpoint]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setting weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = compute_class_weight(\n",
    "    class_weight = 'balanced', \n",
    "    classes = np.unique(train.classes), \n",
    "    y = train.classes\n",
    ")\n",
    "\n",
    "cw = dict(zip(np.unique(train.classes), weights))\n",
    "\n",
    "print(cw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "history = model.fit(\n",
    "    train, \n",
    "    epochs = 50, \n",
    "    validation_data = val, \n",
    "    class_weight = cw, \n",
    "    callbacks = callbacks_list\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc = 'upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "model = load_model(\"C:/Users/antoi/Downloads/model.plk\")\n",
    "\n",
    "test_accu = model.evaluate(test)\n",
    "print(f'The testing accuracy is : {round(test_accu[1]*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the confusion matrix\n",
    "preds = model.predict(test, verbose = 1)\n",
    "\n",
    "predictions = preds.copy()\n",
    "predictions[predictions <= 0.5] = 0\n",
    "predictions[predictions > 0.5] = 1\n",
    "\n",
    "\n",
    "cm = pd.DataFrame(\n",
    "    data = confusion_matrix(\n",
    "        test.classes, \n",
    "        predictions, \n",
    "        labels = [0, 1]\n",
    "    ),\n",
    "    index = [\"Actual Normal\", \"Actual Pneumonia\"], \n",
    "    columns = [\"Predicted Normal\", \"Predicted Pneumonia\"]\n",
    ")\n",
    "\n",
    "sns.heatmap(cm, annot = True, fmt = \"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true = test.classes, y_pred = predictions, target_names = ['NORMAL','PNEUMONIA']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualizing some of the predicted images with percentage %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset()\n",
    "x = np.concatenate([test.next()[0] for i in range(test.__len__())])\n",
    "y = np.concatenate([test.next()[1] for i in range(test.__len__())])\n",
    "\n",
    "#this little code above extracts the images from test Data iterator without shuffling the sequence# x contains image array and y has labels = {0:'NORMAL', 1:'PNEUMONIA'}\n",
    "\n",
    "labels = {0 : \"NORMAL\", 1 : \"PNEUMONIA\"}\n",
    "\n",
    "plt.figure(figsize = (20, 20))\n",
    "\n",
    "for i in range(0+228, 9+228):\n",
    "  plt.subplot(3, 3, (i-228) + 1)\n",
    "\n",
    "  if preds[i, 0] >= 0.5: \n",
    "    out = (f'{round(preds[i][0] * 100, 2)}% probability of being Pneumonia case')\n",
    "  \n",
    "  else: \n",
    "    out = (f'{round((1 - preds[i][0]) * 100, 2)}% probability of being Normal case')\n",
    "\n",
    "  plt.title(f\"{out}\\nActual case : {labels.get(y[i])}\")    \n",
    "  plt.imshow(np.squeeze(x[i]))\n",
    "  plt.axis('off')\n",
    "  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
